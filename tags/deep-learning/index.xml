<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Deep Learning on Teleported.in</title>
    <link>https://teleported.in/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on Teleported.in</description>
    <generator>Hugo -- 0.149.1</generator>
    <language>en-us</language>
    <copyright>2025 Anand Saha.</copyright>
    <lastBuildDate>Thu, 02 Nov 2017 23:27:27 -0400</lastBuildDate>
    <atom:link href="https://teleported.in/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Decoding the ResNet architecture</title>
      <link>https://teleported.in/blog/2017/11/decoding-the-resnet-architecture/</link>
      <pubDate>Thu, 02 Nov 2017 23:27:27 -0400</pubDate>
      <guid>https://teleported.in/blog/2017/11/decoding-the-resnet-architecture/</guid>
      <description>&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://www.fast.ai&#34;&gt;Fast.ai&amp;rsquo;s&lt;/a&gt; 2017 batch kicked off on 30th Oct and &lt;a href=&#34;https://twitter.com/jeremyphoward&#34;&gt;Jeremy Howard&lt;/a&gt; introduced us participants to the ResNet model in the first lecture itself. I had used this model earlier in the passing but got curious to dig into its architecture this time. &lt;em&gt;(In fact in one of my &lt;a href=&#34;https://www.suasnews.com/2017/10/flytbase-releases-ai-platform-drones/&#34;&gt;earlier client projects&lt;/a&gt; I had used Faster RCNN, which uses a ResNet variant under the hood.)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;ResNet was unleashed in 2015 by Kaiming He. et.al. through their paper &lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34;&gt;Deep Residual Learning for Image Recognition&lt;/a&gt; and bagged all the &lt;a href=&#34;http://www.image-net.org/&#34;&gt;ImageNet challenges&lt;/a&gt; including classification, detection, and localization.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Network In Network architecture: The beginning of Inception</title>
      <link>https://teleported.in/blog/2017/10/network-in-network-architecture-the-beginning-of-inception/</link>
      <pubDate>Fri, 20 Oct 2017 23:27:27 -0400</pubDate>
      <guid>https://teleported.in/blog/2017/10/network-in-network-architecture-the-beginning-of-inception/</guid>
      <description>&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;In this post, I explain the &lt;a href=&#34;https://arxiv.org/abs/1312.4400&#34;&gt;&lt;code&gt;Network In Network&lt;/code&gt;&lt;/a&gt;  paper by Min Lin, Qiang Chen, Shuicheng Yan (2013). This paper was quite influential in that it had a new take on convolutional filter design, which inspired the Inception line of deep architectures from Google.&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;Anyone getting introduced to convolutional networks first come across this familiar arrangement of neurons designed by Yann LeCun decades ago:&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;LeNet&#34; loading=&#34;lazy&#34; src=&#34;https://teleported.in/post_images/000-LeNet.png&#34;&gt;
&lt;em&gt;Fig. &lt;a href=&#34;http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf&#34;&gt;LeNet-5&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Yann LeCun&amp;rsquo;s work (&lt;a href=&#34;http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf&#34;&gt;1989&lt;/a&gt;, &lt;a href=&#34;http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf&#34;&gt;1998&lt;/a&gt;) triggered the convolutional approach, which takes into account the inherent structure of the incoming data (mostly image data) while propagating them through the network and learning about them.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
